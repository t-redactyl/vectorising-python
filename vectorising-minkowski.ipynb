{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "* Show picture of Manhattan distance, like walking a city block\n",
    "* Show picture of Euclidean distance, talking the \"direct path\"\n",
    "* Explain formula for Minkowski distance and break it down\n",
    "* Show how this works for two points in 2D:\n",
    "    * For Manhattan distance, we're travelling along the difference on the x-axis and then the distance on the y-axis\n",
    "    * For Euclidean distance, imagine we treat those two x- and y-differences as sides of a triangle, then calculate the hypotenuse.\n",
    "\n",
    "While, again, we can only really comfortably visualise this in 2- and 3D, the logic extends to n-dimensions as with vector spaces.\n",
    "\n",
    "We now know what we need to calculate the Minowski difference, so let's create a simple implementation using loops.\n",
    "\n",
    "Calculation of Minkowski distance:\n",
    "\n",
    "Explain what this is in 2-d space:\n",
    "* Manhattan\n",
    "* Euclidean\n",
    "\n",
    "Then show calculation of this using loops\n",
    "\n",
    "Then work out which linear algebra functions you use to create the optimisation and explain them\n",
    "Then show LA optimisation + timing for various n-dimensions and datasets\n",
    "Split into 2 different functions and get rid of sq forloop for Manhattan and abs forloop for Euclidean\n",
    "Comparing timing to sklearn implementation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Just enough linear algebra to optimise the Minkowski distance\n",
    "\n",
    "In the last blog post, we discussed how to calculate the Manhattan and Euclidean distances from first principles. However, in that post, we did a very manual implementation for a single pair of vectors, which would not generalise well to more than one pair and would become cumbersome for more than a few dimensions. As such, in this blog post we will discuss how to implement the Minkowski distance calculation for vectors of any number of dimensions and for any numbers of pairs. As doing pairwise calculations can become very computationally expensive, we will also discuss how to optimise our distance calculations using some further knowledge from linear algebra.\n",
    "\n",
    "## Our inital attempt\n",
    "Let's start by revisiting our manual implementation of the Euclidean distance:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "6.557438524302"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = [5, 7, 3, 9]\n",
    "Y = [1, 6, 2, 4]\n",
    "i = len(X)\n",
    "p = 2\n",
    "\n",
    "diff_1 = np.abs(X[0] - Y[0]) ** p\n",
    "diff_2 = np.abs(X[1] - Y[1]) ** p\n",
    "diff_3 = np.abs(X[2] - Y[2]) ** p\n",
    "diff_4 = np.abs(X[3] - Y[3]) ** p\n",
    "\n",
    "euclidean_distance_sq = diff_1 + diff_2 + diff_3 + diff_4\n",
    "euclidean_distance = euclidean_distance_sq ** (1 / p)\n",
    "euclidean_distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Right away, we can see one possibility for generalising our code over as many dimensions as we like: we can run all of our absolute difference calculations in a loop. Let's see how this looks:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "diffs = []\n",
    "for element in np.arange(0, i):\n",
    "    diffs.append(np.abs(X[element] - Y[element]) ** p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now have a list containing the distance metrics, which we can then add."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "euclidean_distance_sq = sum(diffs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's bundle this up into our first Minkowski distance function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def calculate_minkowski_distance(X, Y, p):\n",
    "    \"\"\"Calculates the Minkowski distance between two vectors, X and Y. When p = 1, calculates the Manhattan distance, when p = 2, calculates the Euclidean distance.\"\"\"\n",
    "    i = len(X)\n",
    "    diffs = []\n",
    "    for element in np.arange(0, i):\n",
    "        diffs.append(np.abs(X[element] - Y[element]) ** p)\n",
    "    euclidean_distance_sq = sum(diffs)\n",
    "    return euclidean_distance_sq ** (1 / p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we apply it to our two test vectors, we can see we get the exact same answer:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "6.557438524302"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_minkowski_distance(X, Y, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now need a way of applying our newly minted Minkowski distance function to multiple pairs at the same time. What we need to do is compare every vector all other vectors pairwise, therefore the simplest way of doing this is within a nested loop. We'll create an additional vector, $Z$ to compare to $X$ and $Y$. We then combine this into a list of lists along with $X$ and $Y$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "Z = [8, 8, 3, 1]\n",
    "vectors = [X, Y, Z]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What we'll now do is loop over each vector in this list, comparing $X$ with itself, $X$ with $Y$, etc., using two nested forloops."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "distances = []\n",
    "for a in vectors:\n",
    "    tmp_distances = []\n",
    "    for b in vectors:\n",
    "        tmp_distances.append(calculate_minkowski_distance(a, b, 2))\n",
    "    distances.append(tmp_distances)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we can output the pairwise distance matrix to a Pandas DataFrame."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1         2\n0  0.000000  6.557439  8.602325\n1  6.557439  0.000000  7.937254\n2  8.602325  7.937254  0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>6.557439</td>\n      <td>8.602325</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.557439</td>\n      <td>0.000000</td>\n      <td>7.937254</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.602325</td>\n      <td>7.937254</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(distances)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that everything makes sense: vectors compared with themselves have a distance of 0, and we can see the known distance between $X$ and $Y$ is still returned as 6.56. Let's now package this up into a function and see how it performs on when calculating pairwise differences on our beans dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def apply_minkowski_distance(vectors: list, p: int) -> pd.DataFrame:\n",
    "    distances = []\n",
    "    for a in vectors:\n",
    "        tmp_distances = []\n",
    "        for b in vectors:\n",
    "            tmp_distances.append(calculate_minkowski_distance(a, b, p))\n",
    "        distances.append(tmp_distances)\n",
    "    return pd.DataFrame(distances)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a refresher for those of you who may not have read the last blog post, the [dry bean dataset](https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset#) describes the characteristics of 13,611 images of dried beans across 7 different types. There are 16 features describing the beans, such as their area, aspect ratio and roundness. We'll prepare three samples for testing using the Euclidean distance:\n",
    "* A sample of 100 observations using only three of the features (`MajorAxisLength`, `MinorAxisLength` and `roundness`);\n",
    "* All observations using only the above three features; and\n",
    "* The entire dataset with all features.\n",
    "\n",
    "As our function above takes in a list of lists containing each of the vectors, we convert our Pandas DataFrames to this format by first extracting the values of each row using `values` and then converting this to a list using `tolist()`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "beans = pd.read_excel(\"data/Dry_Bean_Dataset.xlsx\")\n",
    "\n",
    "list_sample_1 = beans[[\"MajorAxisLength\", \"MinorAxisLength\", \"roundness\"]][:100].values.tolist()\n",
    "list_sample_2 = beans[[\"MajorAxisLength\", \"MinorAxisLength\", \"roundness\"]].values.tolist()\n",
    "list_sample_3 = beans.drop(columns = [\"Class\"]).values.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then run the pairwise Euclidean distance calculation over each of our samples."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84.5 ms, sys: 34.2 ms, total: 119 ms\n",
      "Wall time: 89.4 ms\n"
     ]
    }
   ],
   "source": [
    "%time list_min_1 = apply_minkowski_distance(list_sample_1, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our small sample with three features finishes relatively quickly."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 47s, sys: 18.2 s, total: 17min 5s\n",
      "Wall time: 16min 56s\n"
     ]
    }
   ],
   "source": [
    "%time list_min_2 = apply_minkowski_distance(list_sample_2, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, when we move up to 100 times that many observations, our operation takes more than 10,000 times as long to complete, clocking in at an eyewatering 17 minutes. It's easy to see why when we look at the code: in our nested forloop we're multiplying every single element by every other element (including itself), meaning that the number of operations we need to complete is the square of the number of vectors. You can confirm this by seeing that our example vector containing $X$, $Y$ and $Z$: we had three vectors, but ended up with 9 calculations in our distance matrix."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 5min 48s, sys: 2min 15s, total: 1h 8min 4s\n",
      "Wall time: 1h 6min 37s\n"
     ]
    }
   ],
   "source": [
    "%time list_min_3 = apply_minkowski_distance(list_sample_3, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that our processing time has just increased approximately fourfold. This makes sense given that we're looping over each element in the vector to get the difference scores needed to calculate our Euclidean distance. As we've jumped from 3 to 16 features, we'd expect a corresponding increase in the processing time for each distance calculation. This calculation of the difference score element-by-element is the first inefficiency we'll tackle. To understand how to do so, let's have a discussion about some of the arithmetic we can do with vectors.\n",
    "\n",
    "## Vector arithmetic\n",
    "\n",
    "Just like with numbers, we can do some simple arithmetic operations with vectors. The first of these is that we can take two vectors with the same number of elements and subtract them. This results in the corresponding elements being lined up and the second subtracted from the first. Let's see an example."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-4, -1, -1, -5])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xm = np.array([5, 7, 3, 9])\n",
    "Ym = np.array([1, 6, 2, 4])\n",
    "\n",
    "Ym - Xm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that by subtracting $Xm$ from $Ym$, we ended up with pairwise subtraction of each element of each, with $Ym_1 - Xm_1 = 1 - 5 = -4$, $Ym_2 - Xm_2 = 6 - 7 = -1$, and so on. You can probably see already that if we can replace the forloop to calculate the difference elementwise in our Minkowski function, we could save quite a lot of processing time.\n",
    "\n",
    "In order to fully replace this functionality, we need to know about two other things we can do with vectors. Using `numpy`, we can apply an [absolute difference function](https://numpy.org/doc/stable/reference/generated/numpy.absolute.html) to each element in the vector. In addition, we can raise each element in a vector to a power (also known as the Hadamard power) using `numpy`'s `power` method. Let's see these both in action."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([4, 1, 1, 5])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(Ym - Xm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see it has worked, with all values now converted to positive. Let's now apply the `power` function:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([16,  1,  1, 25])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(np.abs(Ym - Xm), 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We've now replicated all of the functionality we were including in the loop in our Minkowski function. Let's update it and see whether our performance has improved."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def calculate_minkowski_distance(X, Y, p):\n",
    "    \"\"\"Calculates the Minkowski distance between two vectors, X and Y. When p = 1, calculates the Manhattan distance, when p = 2, calculates the Euclidean distance.\"\"\"\n",
    "    diffs = np.power(np.abs(X - Y), p)\n",
    "    euclidean_distance_sq = sum(diffs)\n",
    "    return euclidean_distance_sq ** (1 / p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a quick sanity check, let's confirm that we get the same answer as with our previous version of the function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "6.557438524302"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_minkowski_distance(Xm, Ym, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having confirmed this, let's test it out with the same samples as previously. We now need to convert these into numpy arrays to be able to exploit the `numpy` vector functions we're using."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "array_sample_1 = beans[[\"MajorAxisLength\", \"MinorAxisLength\", \"roundness\"]][:100].to_numpy()\n",
    "array_sample_2 = beans[[\"MajorAxisLength\", \"MinorAxisLength\", \"roundness\"]].to_numpy()\n",
    "array_sample_3 = beans.drop(columns = [\"Class\"]).to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's now test out how it performs compared to our last implementation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.5 ms, sys: 2.74 ms, total: 55.3 ms\n",
      "Wall time: 53.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time list_min_1 = apply_minkowski_distance(array_sample_1, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 1s, sys: 6.9 s, total: 13min 8s\n",
      "Wall time: 13min 10s\n"
     ]
    }
   ],
   "source": [
    "%time list_min_2 = apply_minkowski_distance(array_sample_2, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 16s, sys: 7.35 s, total: 17min 23s\n",
      "Wall time: 17min 26s\n"
     ]
    }
   ],
   "source": [
    "%time list_min_3 = apply_minkowski_distance(array_sample_3, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that we're getting significantly faster times, especially"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 0,  0,  0,  0],\n        [16,  1,  1, 25],\n        [ 9,  1,  0, 64]],\n\n       [[16,  1,  1, 25],\n        [ 0,  0,  0,  0],\n        [49,  4,  1,  9]],\n\n       [[ 9,  1,  0, 64],\n        [49,  4,  1,  9],\n        [ 0,  0,  0,  0]]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.array([\n",
    "    np.array([5, 7, 3, 9]),\n",
    "    np.array([1, 6, 2, 4]),\n",
    "    np.array([8, 8, 3, 1])\n",
    "])\n",
    "\n",
    "diffs = vectors[:, None, :] - vectors[None, :, :]\n",
    "np.abs(diffs)**2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " * Time this on beans dataset (different subset: small with 3 features, all with 3 features, all with all features)\n",
    "    * 100, 500, 1000, 5000 and 10000 observations with all 16 features\n",
    "    * 1 through to 16 features with 1000 observations\n",
    "* Implement with vector subtraction but still looping (explain relevant linear algebra)\n",
    "* Time this\n",
    "* Implement with broadcasting to get rid of final loop (explain relevant numpy function)\n",
    "* Time this\n",
    "* Compare with sklearn\n",
    "\n",
    "\n",
    "\n",
    "##\n",
    "* Vector subtraction\n",
    "    * Broadcasting vector subtraction (to do this efficiently)\n",
    "* Squaring a vector\n",
    "*\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def calculate_minkowski_distance_vected(array1: np.ndarray,\n",
    "                                        array2: np.ndarray,\n",
    "                                        p: int\n",
    "                                        ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generalised formula for calculating both Manhattan and Euclidean distances. Calculates pairwise distances between every point in two n-dimensional arrays.\n",
    "    array1: first set of points;\n",
    "    array2: second set of points;\n",
    "    p: power parameter which determines the distance metric used, with 1 = Manhattan and 2 = Euclidean.\n",
    "    \"\"\"\n",
    "\n",
    "    diffs = array1[:, None, :] - array2[None, :, :]\n",
    "    abs_diffs = (np.abs(diffs) ** p)\n",
    "    return abs_diffs.sum(axis=-1) ** (1 / p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "array_sample_1 = beans[[\"MajorAxisLength\", \"MinorAxisLength\", \"roundness\"]][:100].to_numpy()\n",
    "array_sample_2 = beans[[\"MajorAxisLength\", \"MinorAxisLength\", \"roundness\"]].to_numpy()\n",
    "array_sample_3 = beans.drop(columns = [\"Class\"]).to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 786 µs, sys: 838 µs, total: 1.62 ms\n",
      "Wall time: 915 µs\n"
     ]
    }
   ],
   "source": [
    "%time array_euclidean_1 = calculate_minkowski_distance_vected(array_sample_1, array_sample_1, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.18 s, sys: 2.19 s, total: 5.37 s\n",
      "Wall time: 5.38 s\n"
     ]
    }
   ],
   "source": [
    "%time array_euclidean_2 = calculate_minkowski_distance_vected(array_sample_2, array_sample_2, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.7 s, sys: 2min 10s, total: 2min 42s\n",
      "Wall time: 5min 16s\n"
     ]
    }
   ],
   "source": [
    "%time array_euclidean_3 = calculate_minkowski_distance_vected(array_sample_3, array_sample_3, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}